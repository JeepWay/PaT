env_id: 2DBpp-v1
n_envs: 4
train_seed: 0
eval_seed: 10
total_timesteps: 3000000
n_eval_episodes: 50
n_eval_seeds: 20
log_dir: logs/ppo
env_kwargs:
  render_mode: human
  bin_channels: 3
  min_items_per_bin: 10
  max_items_per_bin: 20
  area_reward_coef: 0.4
  constant_penalty: -5.0
  action_fail: continue
  reward_type: area
monitor_kwargs:
  info_keywords: !!python/tuple
  - SU
policy_kwargs: &id001
  normalize_images: false
  network: TransfromerNetwork3
  network_kwargs:
    hidden_dim: 200
    position_encode: true
    use_pad_mask: false
    transformer_kwargs:
      d_model: 64
      nhead: 4
      dim_feedforward: 256
      dropout: 0.0
      batch_first: true
      norm_first: false
      num_encoder_layers: 1
      num_decoder_layers: 1
  dist_kwargs:
    mask_strategy: replace
    mask_minus_coef: 15
    mask_replace_coef: -10000000
    update_actor_stratrgy: masked
    entropy_strategy: naive
    invalid_probs_strategy: naive
  mask_type: truth
  ortho_init: true
PPO_kwargs:
  policy: CnnMlpPolicy
  learning_rate: 0.001
  n_steps: 64
  batch_size: 32
  n_epochs: 1
  gamma: 0.99
  gae_lambda: 0.98
  clip_range: 0.2
  normalize_advantage: true
  vf_coef: 0.5
  max_grad_norm: 5
  stats_window_size: 100
  policy_kwargs: *id001
  verbose: 1
  seed: 0
  device: auto
  add_mask_loss: true
  mask_coef: 0.5
  add_entropy_loss: true
  ent_coef: 0.01
  add_invalid_probs: true
  invalid_probs_coef: 0.01
