env_id: 2DBpp-v4
n_envs: 4
train_seed: 0
eval_seed: 10
total_timesteps: 12500000
n_eval_episodes: 20
log_dir: logs/ppo
env_kwargs:
  render_mode: human
  bin_channels: 3
  items_per_bin: 25
  area_reward_coef: 0.4
  constant_penalty: -5.0
  action_fail: continue
  reward_type: area
monitor_kwargs:
  info_keywords: !!python/tuple
  - PE
policy_kwargs: &id001
  normalize_images: false
  network: CnnAttenMlpNetwork1_v1
  network_kwargs:
    hidden_dim: 1600
    position_encode: false
    cnn_shortcut: true
    attention_kwargs:
      out_embed_dim: 64
      normalize: true
  dist_kwargs:
    mask_strategy: minus
    mask_minus_coef: 50
    mask_replace_coef: -15
    update_actor_stratrgy: masked
    entropy_strategy: naive
    invalid_probs_strategy: naive
  mask_type: truth
  ortho_init: true
PPO_kwargs:
  policy: CnnMlpPolicy
  learning_rate: 0.001
  n_steps: 64
  batch_size: 32
  n_epochs: 1
  gamma: 0.99
  gae_lambda: 0.98
  clip_range: 0.2
  normalize_advantage: true
  vf_coef: 0.5
  max_grad_norm: 5
  stats_window_size: 100
  policy_kwargs: *id001
  verbose: 1
  seed: 0
  device: auto
  add_mask_loss: true
  mask_coef: 0.5
  add_entropy_loss: true
  ent_coef: 0.01
  add_invalid_probs: true
  invalid_probs_coef: 0.01
